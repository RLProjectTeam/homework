_LAMBDA = "_lambda"
AC_AGENT = "ac_agent"
ACROBOT = "acrobot"
ACROBOT_POLICY_REINFORCE = "acrobot_policy_reinforce"
ACROBOT_POLICY_REINFORCE_WITH_BASELINE = "acrobot_policy_reinforce_with_baseline"
ACTOR = "actor"
ADAM = "adam"
AGENT = "agent"
AGENT_TYPE = "agent_type"
ALICE = "alice"
ALICE_END_POSITION = "alice_end_position"
ALICE_POSITION = "alice_position"
ALICE_START_POSITION = "alice_start_position"
AVERAGE = "average"
AVERAGE_BATCH_LOSS = "average_batch_loss"
AVERAGE_EPISODIC_REWARD = "average_episodic_reward"
BASE_AGENT = "base_agent"
BASE_MEMORY = "base_memory"
BASE_MODEL = "base_model"
BASE_PATH = "base_path"
BATCH_SIZE = "batch_size"
BOB = "bob"
BOB_END_POSITION = "bob_end_position"
BOB_POSITION = "bob_position"
BOB_START_POSITION = "bob_start_position"
CARTPOLE = "cartpole"
CARTPOLE_POLICY_AC = "cartpole_policy_ac"
CARTPOLE_POLICY_REINFORCE = "cartpole_policy_reinforce"
CARTPOLE_POLICY_REINFORCE_WITH_BASELINE = "cartpole_policy_reinforce_with_baseline"
CONFIG ="config"
COPY = "copy"
CPU = "cpu"
CRITIC = "critic"
CURRENT_EPISODIC_REWARD = "current_episodic_reward"
DATASET = "dataset"
DEBUG = "debug"
DESCRIPTION = "description"
DEVICE = "device"
DIM = "dim"
DIR = "dir"
DOTFULL = ".full"
DOTMIN = ".min"
EARLY_STOPPING_PATIENCE = "early_stopping_patience"
EMBEDDING = "embedding"
EMBEDDING_DIM = "embedding_dim"
ENV = "env"
ENVIRONMENT = "environment"
EPISODE = "Episode"
EPISODE_MEMORY_SIZE = "episode_memory_size"
EPISODE_NUMBER = "episode_number"
EPOCHS = "epochs"
FILE_PATH = "file_path"
FULL = "full"
GAMMA = "gamma"
GENERAL = "general"
GPU = "gpu"
HUMAN = "human"
HUMAN_AGENT = "human_agent"
ID = "id"
INPUT_DIM = "input_dim"
INPUT_SIZE = "input_size"
IS_PREPROCESSED = "is_preprocessed"
IS_SELF_PLAY = "is_self_play"
IS_SELF_PLAY_WITH_MEMORY = "is_self_play_with_memory"
JSON = "json"
K = "k"
LAMBDA = "lambda"
LEARNING_RATE = "learning_rate"
LEARNING_RATE_ACTOR = "learning_rate_actor"
LEARNING_RATE_CRITIC = "learning_rate_critic"
LOAD = "load"
LOAD_PATH = "load_path"
LOAD_TIMESTAMP = "load_timestamp"
LOG = "log"
LOSS = "loss"
LSTM_MEMORY = "lstm_memory"
MAX_MEMORY_SIZE = "max_memory_size"
MAX_STEPS_PER_EPISODE = "max_steps_per_episode"
MAX_STEPS_PER_EPISODE_SELFPLAY = "max_steps_per_episode_selfplay"
MAZEBASE = "mazebase"
MAZEBASE_POLICY = "mazebase_policy"
MAZEBASE_POLICY_AC = "mazebase_policy_ac"
MAZEBASE_POLICY_REINFORCE = "mazebase_policy_reinforce"
MAZEBASE_POLICY_REINFORCE_WITH_BASELINE = "mazebase_policy_reinforce_with_baseline"
MEMORY =  "memory"
MEMORY_SIZE = "memory_size"
MEMORY_TYPE = "memory_type"
MIN = "min"
MODEL = "model"
MOUNTAINCAR = "mountaincar"
MOUNTAINCAR_POLICY_REINFORCE = "mountaincar_policy_reinforce"
MOUNTAINCAR_POLICY_REINFORCE_WITH_BASELINE = "mountaincar_policy_reinforce_with_baseline"
NAME = "name"
NEXT_STATE = "next_state"
NP_RANDOM_STATE = "np_random_state"
NUM_ACTIONS = "num_actions"
NUM_EPOCHS = "num_epochs"
NUM_OPTIMIZERS = "num_optimizers"
OBSERVATION = "observation"
OPTIMISER = "optimiser"
OUTPUT_DIM = "output_dim"
OUTPUTS = "outputs"
PATH = "path"
PERSIST_PER_EPOCH = "persist_per_epoch"
PLOT = "plot"
POLICY = "policy"
POSITION = "position"
PRECISION = "precision"
PTB = "ptb"
PYTHON_RANDOM_STATE = "python_random_state"
PYTORCH_RANDOM_STATE = "pytorch_random_state"
RANDOM = "random"
RANDOM_AGENT = "random_agent"
RECALL = "recall"
REINFORCE = "reinforce"
REINFORCE_AGENT = "reinforce_agent"
REINFORCE_BASELINE = "reinforce_baseline"
REINFORCE_BASELINE_AGENT = "reinforce_baseline_agent"
REVERSE = "reverse"
REWARD = "reward"
REWARD_SCALE = "reward_scale"
RMSPROP = "rmsprop"
SAVE_DIR = "save_dir"
SCALAR_PATH = "scalar_path"
SEED = "seed"
SELFPLAY = "selfplay"
SELFPLAY_POLICY_REINFORCE = "selfplay_policy_reinforce"
SELFPLAY_POLICY_REINFORCE_WITH_BASELINE = "selfplay_policy_reinforce_with_baseline"
SGD = "sgd"
SHARED_FEATURES = "shared_features"
SHARED_FEATURES_SIZE = "shared_features_size"
STATE_DICT = "state_dict"
TARGET = "target"
TARGET_TO_SELFPLAY_RATIO  = "target_to_selfplay_ratio"
TB = "tb"
TEST = "test"
TEST_ACCURACY = "test_accuracy"
TEST_LOSS = "test_loss"
TEST_MACRO_FSCORE = "test_macro_fscore"
TEST_MICRO_FSCORE = "test_micro_fscore"
TEST_NEG = "test_neg"
TEST_NO_EDGE = "test_no_edge"
TEST_POS = "test_pos"
TEST_TIME = "test_time"
TIME = "time"
TIME_ALICE = "time_alice"
TIME_BOB = "time_bob"
TIMESTAMP = "timestamp"
TRAIN = "train"
TRAIN_ACCURACY = "train_accuracy"
TRAIN_LOSS = "train_loss"
TRAIN_TIME = "train_time"
TRUE = "true"
TYPE = "type"
USE_BASELINE = "use_baseline"
USE_MIN = "use_min"
USE_NEURAL_BASELINE = "use_neural_baseline"
USE_PRETRAINED_EMBEDDING = "use_pretrained_embedding"
USE_SPARSE_EMBEDDING = "use_sparse_embedding"
VAL = "val"
VAL_ACCURACY = "val_accuracy"
VAL_LOSS = "val_loss"
VAL_MACRO_FSCORE = "val_macro_fscore"
VAL_MICRO_FSCORE = "val_micro_fscore"
VAL_TIME = "val_time"
UNDO = "undo"
SELFPLAY_TYPE = "selfplay_type"
STDDEV = "stddev"